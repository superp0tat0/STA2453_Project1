{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from time import sleep\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Toronto%2C+ON', 'Waterloo%2C+ON', 'Montreal%2C+QC', 'Vancouver%2C+BC', 'Calgary%2C+AB', 'Ottawa%2C+ON', 'Québec+City%2C+QC', 'Brampton%2C+ON', 'Halifax%2C+NS', 'Hamilton%2C+ON', 'Surrey%2C+BC', 'Victoria%2C+BC', 'Kitchener%2C+ON', 'Winnipeg%2C+MB', 'Edmonton%2C+AB']\n",
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 1000\n",
    "header = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\" ,'referer':'https://www.google.com/'}\n",
    "\n",
    "results = []\n",
    "for i in tqdm.notebook.tqdm(range(len(cities))):\n",
    "    for start in range(0, max_results_per_city, 100):\n",
    "        url = \"https://ca.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=25&l=\"+cities[i]+\"&fromage=any&limit=100&start=\"+str(start)+\"&sort=&psf=advsrch\"\n",
    "        html = requests.get(url, headers = header)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        if(len(soup.find_all('script', {'src':'https://www.google.com/recaptcha/api.js'}))==1):\n",
    "            print('Captcha error(', cities[i],'): Retry in some time or use proxy.')\n",
    "            break\n",
    "        for row in soup.find_all('div', {'class':'jobsearch-SerpJobCard unifiedRow row result'}):\n",
    "            results.append(row)\n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_backup = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.DataFrame(columns=['location', 'title', 'company', 'salary', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc(row):\n",
    "    try:\n",
    "        return row.find('span', {'class':'location'}).text\n",
    "    except: return 'NA'\n",
    "\n",
    "\n",
    "def get_comp(row):\n",
    "    try:\n",
    "        return row.find('span', {'class':'company'}).text.replace('\\n','')\n",
    "    except: return 'NA'\n",
    "    \n",
    "def get_job(row):\n",
    "    try:\n",
    "        return row.find('a', {'data-tn-element':'jobTitle'}).text.replace('\\n','')\n",
    "    except: return 'NA'\n",
    "    \n",
    "        \n",
    "def get_sal(row):\n",
    "    try:\n",
    "        return row.find('span', {'class':'salaryText'}).text.replace('\\n','')\n",
    "    except: return 'NA'\n",
    "    \n",
    "    \n",
    "def get_desc(row):\n",
    "    try:\n",
    "        return row.find('div', {'class':'summary'}).text.replace('\\n','')\n",
    "    except: return 'NA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    location = get_loc(result)\n",
    "    title = get_job(result)\n",
    "    company = get_comp(result)\n",
    "    salary = get_sal(result)\n",
    "    desc = get_desc(result)\n",
    "    jobs.loc[len(jobs)] = [location, title, company, salary, desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jobs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = jobs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv('scraped_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('scraped_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = scrapped_data[scrapped_data.salary.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = salaries[salaries.location != 'Münchberg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_salary = []\n",
    "\n",
    "for i in salaries.salary:        \n",
    "    if 'an hour' in i:\n",
    "        i = i.replace('an hour', '').replace('$', '').replace('from', '').replace('From','')\n",
    "        a = i.split('-')\n",
    "        if(len(a) == 2):\n",
    "            a = [float(x.strip().replace(',','')) for x in a]\n",
    "            preprocess_salary.append(np.mean([float(b) for b in a])*8*300)\n",
    "        else:\n",
    "            a[0] = a[0].strip().replace(',','')\n",
    "            preprocess_salary.append(float(a[0])*8*300)\n",
    "            \n",
    "    elif 'a week' in i:\n",
    "        i = i.replace('a week', '').replace('$', '').replace('from', '').replace('From','')\n",
    "        a = i.split('-')\n",
    "        print(a)\n",
    "        if(len(a) == 2):\n",
    "            a = [float(x.strip().replace(',','')) for x in a]\n",
    "            preprocess_salary.append(np.mean([float(b) for b in a])*52)\n",
    "        else:\n",
    "            a[0] = a[0].strip().replace(',','')\n",
    "            preprocess_salary.append(float(a[0])*52)\n",
    "    \n",
    "    elif 'a month' in i:\n",
    "        i = i.replace('a month', '').replace('$', '').replace('from', '').replace('From','')\n",
    "        a = i.split('-')\n",
    "        if(len(a) == 2):\n",
    "            a = [float(x.strip().replace(',','')) for x in a]\n",
    "            preprocess_salary.append(np.mean([float(b) for b in a])*12)\n",
    "        else:\n",
    "            a = [float(x.strip().replace(',','')) for x in a]\n",
    "            preprocess_salary.append(float(a[0])*12)\n",
    "    elif 'a year' in i:\n",
    "        i = i.replace('a year', '').replace('$', '').replace('from', '').replace('From','')\n",
    "        a = i.split('-')\n",
    "        if len(a) == 2:\n",
    "            a = [float(x.strip().replace(',','')) for x in a]\n",
    "            preprocess_salary.append(np.mean([float(b) for b in a]))\n",
    "        else:\n",
    "            a[0] = a[0].strip().replace(',','')\n",
    "            preprocess_salary.append(float(a[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in salaries.salary:\n",
    "    if len(i.split('-')) != 1 and len(i.split('-')) != 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preprocess_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.salary = preprocess_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = salaries[salaries['location'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "preprocessed_data.to_csv('final_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "median_salary = np.median(salaries.salary)\n",
    "median_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries['high_salary'] = [1 if i > median_salary else 0 for i in salaries.salary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.head()\n",
    "print(len(salaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "states = []\n",
    "\n",
    "for loc in salaries.location:\n",
    "    items = loc.split(',')\n",
    "    cities.append(items[0])\n",
    "    states.append(items[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only_states = []\n",
    "for state in states:\n",
    "    only_states.append(re.search(r'\\w+', state).group(0))\n",
    "print(len(only_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries['city'] = cities\n",
    "salaries['state'] = only_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.city = salaries.city + \", \" + salaries.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in salaries.state:\n",
    "    if len(i) > 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.city.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "salaries.city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dummies = pd.get_dummies(salaries.city)\n",
    "\n",
    "X_city = city_dummies\n",
    "y_city = salaries.high_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_city, y_city, test_size=0.3, random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300, random_state=90)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print (\"Accuracy Score:\", acc.round(3))\n",
    "\n",
    "s = cross_val_score(rfc, X_city, y_city, cv=10, n_jobs=-1)\n",
    "print (\"Cross Validation Score:\\t{:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_city.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_medians = []\n",
    "for i in X_city.columns:\n",
    "    feature_medians.append(np.median(salaries[salaries.city == i].salary))\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['over_or_under'] = [1 if i > median_salary else 0 for i in feature_importances.median_salary]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "salaries_w_desc = salaries[salaries.summary.notnull()]\n",
    "\n",
    "X_summ = salaries_w_desc.summary\n",
    "y_summ = salaries_w_desc.high_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=\"english\")\n",
    "cv.fit(X_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_summ_trans = pd.DataFrame(cv.transform(X_summ).todense(), columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.asmatrix(X_summ_trans), y_summ, test_size=0.3,\n",
    "                                                    random_state=59, stratify=y_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = X_summ_trans.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.to_csv('indeed-words.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(200, random_state=59)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print(\"Accuracy Score:\", acc.round(3))\n",
    "\n",
    "s = cross_val_score(rfc, X_summ_trans.values, y_summ.values, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_summ_trans.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_medians = []\n",
    "feature_means = []\n",
    "for i in X_summ_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc.summary.str.lower().str.contains(i)].salary))\n",
    "    feature_means.append(np.mean(salaries_w_desc[salaries_w_desc.summary.str.lower().str.contains(i)].salary))\n",
    "\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['mean_salary'] = feature_means\n",
    "feature_importances['over_or_under'] = [1 if i > median_salary else 0 for i in feature_importances.median_salary]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Only title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_w_desc = salaries[salaries.summary.notnull()]\n",
    "\n",
    "X_title = salaries_w_desc.title\n",
    "y_title = salaries_w_desc.high_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=\"english\")\n",
    "cv.fit(X_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title_trans = pd.DataFrame(cv.transform(X_title).todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_title_trans, y_title, test_size=0.3, random_state=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(200, random_state=59)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print(\"Accuracy Score:\", acc.round(3))\n",
    "\n",
    "s = cross_val_score(rfc, X_title_trans.values, y_title.values, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_title_trans.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_medians = []\n",
    "feature_means = []\n",
    "for i in X_title_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc.title.str.lower().str.contains(i)].salary))\n",
    "    feature_means.append(np.mean(salaries_w_desc[salaries_w_desc.title.str.lower().str.contains(i)].salary))\n",
    "\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['mean_salary'] = feature_means\n",
    "feature_importances['over_or_under'] = [1 if i > median_salary else 0 for i in feature_importances.median_salary]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Title CV, Summary CV, and Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_w_desc = data[data.summary.notnull()].reset_index()\n",
    "city_dummies = pd.get_dummies(salaries_w_desc.city)\n",
    "\n",
    "X = pd.concat([city_dummies, X_title_trans, X_summ_trans], axis=1)\n",
    "y = salaries_w_desc.high_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.3, random_state=1234, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(500, random_state=59)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print(\"Accuracy Score:\", acc.round(3))\n",
    "\n",
    "s = cross_val_score(rfc, X.values, y.values, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_medians = []\n",
    "for i in city_dummies.columns:\n",
    "    feature_medians.append(np.median(salaries[salaries.city == i].salary))\n",
    "for i in X_title_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc.title.str.lower().str.contains(i)].salary))\n",
    "for i in X_summ_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc.summary.str.lower().str.contains(i)].salary))\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['over_or_under'] = [1 if i > median_salary else 0 for i in feature_importances.median_salary]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
